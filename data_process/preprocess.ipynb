{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmUzFOzwXlAp"
      },
      "source": [
        "Include march_crime.csv, Demograph.csv, no_dupes.csv and eve_new.csv\n",
        "Take input.csv as training data for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMr69LiRybtM",
        "outputId": "ac84f0d9-ce54-40f3-85f1-f32d71eb4c9d"
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.sparse\n",
        "import pandas as pd\n",
        "crimemarch = pd.read_csv(\"march_crime.csv\")\n",
        "demo = pd.read_csv(\"Demograph.csv\")\n",
        "d = demo[[\"NEIGHBORHO\", \"pop\", \"white\"]]\n",
        "\n",
        "beat_group = crimemarch.groupby([\"neighborhood\", \"beat\"], as_index=False).count()\n",
        "beat_group = beat_group[[\"neighborhood\", \"beat\", \"offense_id\"]]\n",
        "beat_group = beat_group.sort_values(by=[\"beat\", \"offense_id\"])\n",
        "beat_group_2 = beat_group.groupby([\"beat\"]).max(\"offense_id\")\n",
        "\n",
        "beat_group = beat_group_2.merge(beat_group, on=[\"beat\", \"offense_id\"], how=\"left\")\n",
        "n = []\n",
        "for i in beat_group[\"neighborhood\"].tolist():\n",
        "  for j in d[\"NEIGHBORHO\"]:\n",
        "    if i in j:\n",
        "      n.append(j)\n",
        "      break\n",
        "beat_group[\"NEIGHBORHO\"] = n\n",
        "beat_group = beat_group.merge(d, on=\"NEIGHBORHO\", how=\"left\")\n",
        "beat_group.head()\n",
        "model_data = pd.read_csv(\"no_dupes.csv\")\n",
        "model_data[\"beat\"] = model_data[\"beat\"].astype(\"str\")\n",
        "beat_group  = beat_group[[\"beat\", \"offense_id\"]]\n",
        "print(beat_group)\n",
        "model_data = model_data.merge(beat_group, on=\"beat\", how=\"left\")\n",
        "events = pd.read_csv(\"eve_new.csv\")\n",
        "print(events)\n",
        "events_count = events.groupby(\"beat\", as_index=False).count()\n",
        "\n",
        "events_count[\"events_count\"] = events_count[\"date\"]\n",
        "events_count[\"beat\"] = events_count[\"beat\"].astype(str)\n",
        "model_data = model_data.merge(events_count, on=\"beat\",  how=\"left\")\n",
        "model_data[\"true_crime\"] = model_data[\"offense_id\"]\n",
        "model_data.to_csv(\"input.csv\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   beat  offense_id\n",
            "0   101           6\n",
            "1   102          18\n",
            "2   103          22\n",
            "3   104           8\n",
            "4   105           7\n",
            "..  ...         ...\n",
            "74  610          11\n",
            "75  611          12\n",
            "76  612           9\n",
            "77  613          11\n",
            "78  614          11\n",
            "\n",
            "[79 rows x 2 columns]\n",
            "         date  beat\n",
            "0    2/3/2021   605\n",
            "1    3/3/2021   501\n",
            "2    6/3/2021   301\n",
            "3    6/3/2021   111\n",
            "4    7/3/2021   104\n",
            "5    8/3/2021   507\n",
            "6   13/3/2021   209\n",
            "7   14/3/2021   507\n",
            "8   15/3/2021   507\n",
            "9   16/3/2021   212\n",
            "10  19/3/2021   507\n",
            "11  20/3/2021   507\n",
            "12  20/3/2021   303\n",
            "13  23/3/2021   201\n",
            "14  27/3/2021   511\n",
            "15  28/3/2021   106\n",
            "16  28/3/2021   209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jcsv8X4OXG4"
      },
      "source": [
        "Recompile predictions to include all beats.\n",
        "Include source_data.csv, final_output.csv(model predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DCjrNQu5V95"
      },
      "source": [
        "source = pd.read_csv(\"source_data.csv\")\n",
        "final = pd.read_csv(\"final_output.csv\")\n",
        "source = source[[\"Beat\", \"NEIGHBORHO\"]]\n",
        "source = source.merge(final, on=\"NEIGHBORHO\", how=\"left\")\n",
        "source.head(n=20)\n",
        "source.to_csv(\"output_update.csv\")\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiQytJBlwJs7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}